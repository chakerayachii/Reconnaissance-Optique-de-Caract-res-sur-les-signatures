{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e810dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f05b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='/ml/pymnist',  #Sélectionnez le Répertoire racine des données\n",
    "                            train=True,#Sélectionner un ensemble d'entraînement\n",
    "                            transform=None,# Le prétraitement des données n'est pas envisagé \n",
    "                            download=True # Téléchargement d'images depuis le Web \n",
    ")\n",
    "\n",
    "test_dataset = dsets.MNIST(root='/ml/pymnist',#Sélectionnez le Répertoire racine des données\n",
    "                           train=False,#Sélectionnez l'ensemble de test\n",
    "                           transform=None,# Aucun prétraitement des données n'est envisagé \n",
    "                           download=True # Téléchargement d'images depuis le Web \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b92cb5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yakoubi\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:75: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\Users\\Yakoubi\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train=train_dataset.train_data.numpy().reshape(-1,28*28)  #Oui.6Dix mille.28X28Photos de, Convertir en un tableau unidimensionnel \n",
    "#print(x_train.shape)  #Produits;(60000, 784)  \n",
    "\n",
    "imgIndex = 24\n",
    "\n",
    "# Prenez une des photos \n",
    "x1 = x_train[imgIndex].reshape(28,28)  # Convertir un tableau unidimensionnel en matrice de second ordre  28X28, Restaurer la matrice d'image \n",
    "#print(x1)  #Produits28X28Matrice bidimensionnelle\n",
    "\n",
    "\n",
    "y_train = train_dataset.train_labels.numpy()  #Convertir ennumpyDonnées\n",
    "#print(y_train.shape) #Produitstorch.Size([60000]) ,Oui.60000 Étiquette de l'image , Correspond exactement au nombre d'images ci - dessus \n",
    "\n",
    "y1 = y_train[imgIndex]\n",
    "#print(y1)  #Produits：5\n",
    "\n",
    "#Affichage de l'image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x1,cmap=plt.cm.binary)  # Afficher les paramètres de l'image \n",
    "plt.title(\"number:\" + str(y1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0334a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yakoubi\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:75: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\Users\\Yakoubi\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "C:\\Users\\Yakoubi\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\Yakoubi\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch is： 0\n",
      "loss:  2.311159871023115\n",
      "loss:  0.7918173232566014\n",
      "loss:  0.7595045031886343\n",
      "loss:  0.50698236899967\n",
      "loss:  0.5453771725616731\n",
      "loss:  0.635361022976755\n",
      "current epoch is： 1\n",
      "loss:  0.4547445007621296\n",
      "loss:  0.5113726306377483\n",
      "loss:  0.46223860318142074\n",
      "loss:  0.30612529284846535\n",
      "loss:  0.5324756439087059\n",
      "loss:  0.30769637878126765\n",
      "current epoch is： 2\n",
      "loss:  0.30204827165524384\n",
      "loss:  0.26597029588185583\n",
      "loss:  0.3702339340855311\n",
      "loss:  0.22381662544322306\n",
      "loss:  0.46556272857372166\n",
      "loss:  0.318826222132868\n",
      "current epoch is： 3\n",
      "loss:  0.31661723094441496\n",
      "loss:  0.38188258399500824\n",
      "loss:  0.22901689312794146\n",
      "loss:  0.5397577138354152\n",
      "loss:  0.328461005361846\n",
      "loss:  0.18643804535559294\n",
      "current epoch is： 4\n",
      "loss:  0.30125316143395475\n",
      "loss:  0.42060568759326217\n",
      "loss:  0.32033289914256174\n",
      "loss:  0.43604423759475225\n",
      "loss:  0.2412180770856841\n",
      "loss:  0.13826898348865746\n",
      "Précision： 86.53 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 100\n",
    "#MNIST dataset\n",
    "train_dataset = dsets.MNIST(root='/ml/pymnist',  #Sélectionnez le Répertoire racine des données\n",
    "                            train=True,#Sélectionner un ensemble d'entraînement\n",
    "                            transform=None,# Le prétraitement des données n'est pas envisagé \n",
    "                            download=False # Téléchargement d'images depuis le Web , Premier choix True\n",
    ")\n",
    "\n",
    "test_dataset = dsets.MNIST(root='/ml/pymnist',#Sélectionnez le Répertoire racine des données\n",
    "                           train=False,#Sélectionnez l'ensemble de test\n",
    "                           transform=None,# Aucun prétraitement des données n'est envisagé \n",
    "                           download=False# Téléchargement d'images depuis le Web , Premier choix True\n",
    ")\n",
    "\n",
    "x_train=train_dataset.train_data.numpy().reshape(-1,28*28)\n",
    "y_train_tmp=train_dataset.train_labels.reshape(train_dataset.train_labels.shape[0],1)\n",
    "y_train=torch.zeros(y_train_tmp.shape[0],10).scatter_(1,y_train_tmp,1).numpy()\n",
    "#print(y_train)\n",
    "\n",
    "x_test = test_dataset.test_data.numpy().reshape(-1,28*28)\n",
    "y_test_tmp = test_dataset.test_labels.reshape(test_dataset.test_labels.shape[0],1)\n",
    "y_test = torch.zeros(y_test_tmp.shape[0],10).scatter_(1,y_test_tmp,1).numpy()\n",
    "\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.x=None\n",
    "        return\n",
    "    def forward(self,x):\n",
    "        self.x=np.maximum(0,x)\n",
    "        out=self.x\n",
    "        return out\n",
    "    def backward(self,dout):\n",
    "        dx=dout\n",
    "        dx[self.x<=0]=0\n",
    "        #print(\"dout:\",dx)\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self,W,b):\n",
    "        self.W=W\n",
    "        self.b=b\n",
    "        self.x=None\n",
    "        self.dW=None\n",
    "        self.db=None\n",
    "        return\n",
    "    def forward(self,x):\n",
    "        self.x=x\n",
    "        out=np.dot(x,self.W)+self.b\n",
    "        return out\n",
    "    def backward(self,dout):\n",
    "        dx=np.dot(dout,self.W.T)\n",
    "        self.dW=np.dot(self.x.T,dout)\n",
    "        self.db=np.sum(dout,axis=0)\n",
    "        #print(\"db:\",self.db)\n",
    "        return dx\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss=None #Pertes\n",
    "        self.p=None #softmaxProduits\n",
    "        self.y=None # Les données de surveillance représentent la valeur réelle ,one-hot vector\n",
    "        return\n",
    "    def softmax(self,x):\n",
    "        if x.ndim==2:  #ndimRenvoie la dimension du tableau,Un seul nombre est retourné,Ce nombre représente la dimension du tableau.\n",
    "            c=np.max(x,axis=1)\n",
    "            x=x.T-c # Décision de débordement \n",
    "            y=np.exp(x)/np.sum(np.exp(x),axis=0)\n",
    "            return y.T\n",
    "        c=np.max(x)\n",
    "        exp_x = np.exp(x-c)\n",
    "        return exp_x/np.sum(exp_x)\n",
    "    def cross_entropy_error(self,p,y):\n",
    "        delta=1e-7\n",
    "        batch_size=p.shape[0]\n",
    "        return -np.sum(y*np.log(p+delta))/batch_size\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        self.y=y\n",
    "#         print(\"self.y\",self.y)\n",
    "        self.p=self.softmax(x)\n",
    "        self.loss=self.cross_entropy_error(self.p,self.y)\n",
    "        #print(self.loss)\n",
    "        return self.loss\n",
    "    def backward(self,dout=1):\n",
    "        batch_size=self.y.shape[0]\n",
    "        dx=(self.p-self.y)/batch_size  # Les paramètres prédisent l'erreur d'acquisition d'un petit lot de données \n",
    "#         print(dx.shape) #(100, 10)\n",
    "        return dx\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self,input_size,hidden_size,output_size,weight_init_std=0.01):\n",
    "        #Poids d'initialisation\n",
    "        self.params={}\n",
    "        self.params['W1']=weight_init_std*np.random.randn(input_size,hidden_size)   #Masquer les poids des couches\n",
    "#         print(self.params['W1'])\n",
    "\n",
    "        self.params['b1']=np.zeros(hidden_size)  # Masquer la valeur offset de la couche \n",
    "        self.params['W2']=weight_init_std*np.random.randn(hidden_size,output_size) #Poids de la couche de sortie\n",
    "        self.params['b2']=np.zeros(output_size)  # Valeur offset de la couche de sortie \n",
    "\n",
    "        # Générer une couche de réseau neuronal \n",
    "        self.layers=OrderedDict() #Dictionnaire ordonné;BasicdictImpossible de garantir la séquence,keys Mapping to Hashi , Et cette valeur n'est pas stockée séquentiellement dans le tableau de hachage . Donc, rencontrer pour s'assurer que le Dictionnaire keysScène ordonnée,On va l'utiliser.OrderedDict.\n",
    "        self.layers['Affine1']=Affine(self.params['W1'],self.params['b1'])  # Les neurones qui génèrent des couches cachées \n",
    "        self.layers['Relu1']=Relu()  # Générer une fonction d'activation pour les couches cachées  \n",
    "        self.layers['Affine2']=Affine(self.params['W2'],self.params['b2'])  # Les neurones qui génèrent la couche de sortie \n",
    "        self.layers['Relu2']=Relu()  # Générer une fonction d'activation pour la couche de sortie  \n",
    "        self.lastLayer = SoftmaxWithLoss()   \n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self,x):\n",
    "        for layer in self.layers.values(): # Chaque couche se propage vers l'avant \n",
    "            x=layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    #x：Saisie des données,y：Données de surveillance\n",
    "    def loss(self,x,y):\n",
    "        p=self.predict(x)  # Une fois prévu \n",
    "        return self.lastLayer.forward(p,y)  # La dernière couche a fait une propagation vers l'avant \n",
    "    \n",
    "    def accuracy(self,x,y):\n",
    "        #Prévoir\n",
    "        p=self.predict(x) \n",
    "        #print(\"p:\",p.shape)  #p: (10000, 10)\n",
    "        p=np.argmax(p,axis=1) #argmax Renvoie l'indice pour la valeur maximale d'une colonne \n",
    "        #print(\"p:\",p.shape)  #p: (10000,)\n",
    "        y=np.argmax(y,axis=1)\n",
    "\n",
    "        accuracy=np.sum(p==y)/float(x.shape[0])  # Prévoir toutes les données , Voir combien de bons \n",
    "        return accuracy\n",
    "\n",
    "    \"\"\"\n",
    "     Réaliser le gradient , Mais les poids n'ont pas été modifiés \n",
    "    \"\"\"\n",
    "    def gradient(self,x,y):\n",
    "        #forward\n",
    "        self.loss(x,y)  \n",
    "\n",
    "        #backward\n",
    "        dout=1\n",
    "        dout=self.lastLayer.backward(dout) #(100, 10) # Erreur dans un lot de données \n",
    "#         print(\"dout:\",dout)  # Erreur dans chaque neurone de sortie \n",
    "\n",
    "        layers=list(self.layers.values())\n",
    "        #print(\"layers:\",layers)\n",
    "        layers.reverse()  #Inversion\n",
    "        for layer in layers:\n",
    "            dout=layer.backward(dout)  # Ici, la propagation vers l'avant couche par couche est réalisée ,ReLU2 -》 Affine2 -》ReLU1 -》Affine1\n",
    "#             print(\"dout:\",dout)\n",
    "\n",
    "        #Réglage\n",
    "        grads={}\n",
    "        grads['W1'],grads['b1']=self.layers['Affine1'].dW,self.layers['Affine1'].db\n",
    "        grads['W2'],grads['b2']=self.layers['Affine2'].dW,self.layers['Affine2'].db\n",
    "        \n",
    "        return grads\n",
    "\n",
    "train_size = x_train.shape[0] \n",
    "iters_num = 600\n",
    "learning_rate = 0.001\n",
    "epoch = 5\n",
    "batch_size = 100\n",
    "\n",
    "network = TwoLayerNet(input_size = 784,hidden_size = 50,output_size = 10)\n",
    "\n",
    "#Formation,Formation par lots： Diviser le total en epochLot, Après l'entraînement d'un lot avant l'entraînement suivant \n",
    "    # Notez que l'entraînement ne conserve pas les poids de façon permanente \n",
    "for i in range(epoch): #Formation par lots\n",
    "    print(\"current epoch is：\", i)\n",
    "    for num in range(iters_num):\n",
    "        batch_mask = np.random.choice(train_size,batch_size)  #>>> np.random.choice(5, 3)   Produitsarray([0, 3, 4]) # random\n",
    "                                                                #Intrain_size Sélection aléatoire dans la gamme batch_sizeNombre, Former un tableau unidimensionnel \n",
    "        #print(batch_mask)\n",
    "        x_batch = x_train[batch_mask]  # Sélectionnez un petit lot dans les données totales \n",
    "        #print(x_batch.shape)\n",
    "        y_batch = y_train[batch_mask]\n",
    "\n",
    "##########################Méthode de descente par gradient####################################\n",
    "        grad = network.gradient(x_batch,y_batch)\n",
    "       #print(\"grad\",grad)\n",
    "\n",
    "        for key in ('W1','b1','W2','b2'):\n",
    "            network.params[key] -= learning_rate*grad[key]  # Réaliser l'apprentissage par Gradient descendant \n",
    "############################################################################\n",
    "        loss = network.loss(x_batch,y_batch)  # Calculer la valeur de la perte\n",
    "        if num % 100 ==0:\n",
    "            print(\"loss: \",loss)\n",
    "#print(x_test.shape,y_test.shape)\n",
    "print('Précision：',network.accuracy(x_test,y_test)*100,'%')  #Oui.10000 Une image pour l'identifier , Regardez le taux correct \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " Nous avons choisi une image au hasard pour la reconnaître \n",
    "\"\"\"\n",
    "x_train=train_dataset.train_data.numpy().reshape(-1,28*28)  #Oui.6Dix mille.28X28Photos de, Convertir en un tableau unidimensionnel \n",
    "#print(x_train.shape)  #Produits;(60000, 784)  \n",
    "\n",
    "import random\n",
    "imgIndex = random.randint(0,x_train.shape[0]) #In60000 Choisissez l'une des images \n",
    "imgIndex1 = 24\n",
    "\n",
    "# Prenez une des photos \n",
    "x1 = x_train[imgIndex1].reshape(28,28)  # Convertir un tableau unidimensionnel en matrice de second ordre  28X28, Restaurer la matrice d'image \n",
    "#print(x1)  #Produits28X28Matrice bidimensionnelle\n",
    "\n",
    "p = network.predict(x1.reshape(-1,28*28))\n",
    "p = np.argmax(p,axis=1)\n",
    "# print(\"Prévisions：\",p)\n",
    "\n",
    "y_train = train_dataset.train_labels.numpy()  #Convertir ennumpyDonnées\n",
    "#print(y_train.shape) #Produitstorch.Size([60000]) ,Oui.60000 Étiquette de l'image , Correspond exactement au nombre d'images ci - dessus \n",
    "\n",
    "y1 = y_train[imgIndex1]\n",
    "#print(y1)  #Produits：5\n",
    "\n",
    "#Affichage de l'image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x1,cmap=plt.cm.binary)  # Afficher les paramètres de l'image \n",
    "plt.title(\"predicted number:\" + str(y1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a42cc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b354177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
